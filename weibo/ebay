ebay架构的一些优化工作：
应用程：
把功能切分分散为多个应用模块。模块负责一小块功能
单独进行维护，部署和扩容。每个模块与后端的一小块资源进行交互
例如销售计量模块，搜索模块进行了分离。
数据层：
对数据集合进行了区分。数据分为用户数据，货物数据，和购买数据。
这些数据分别存储在不同的逻辑数据表里。分散到多个物理集合上。
这样就可以独立地针对的数据进行扩容。


Split Horizontally

真正的系统压力不在于应用程序，而在于数据层。由于应用层都是无状态的，
所以每次请求过来的时候使用负载均衡将请求进行路由。应用程序完全可以new一个
新的进程或者实例来跑业务逻辑。所以扩容应用层无压力。
但是数据是有状态的。对于用户账户数据，目前ebay采用了20台主机，每台主机
存了1/20的用户数据。其他一样
（但是这种会带来数据库扩容的问题，怎么解决？）
(Tmem是怎么解决这种问题的，数据层的扩容)


避免分布式事务

在各种资源上使用分布式事务，使用two-phase commit（了解下这是什么）
来保证所有资源的更新或者回滚。但是，这个会带来额外的系统开销。对于
扩容，性能和请求延迟都可能造成影响。事实证明你不能拥有所有的东西。
在多个系统之间保证数据的立马一致并不是必须的事情。CAP理论
C  一致性，A可用性，P  分区容忍性。 
任何时候你都只可以拥有其中的两个而已。对于一个高并发的网站，我们需要
选择分区容忍性。方便快速的扩容支持业务请求量的增长。对于一个24×7 小时不断
运行的站点，我们应该考虑可用性为第一位。数据的立马一致性需要做出让步。
(对于这个理论的场景理解，怎么去做方案优化来达到对于这些特性的选择)
在eaby，我们完全不用分布式的事务，没有two-phase  commit
我们并没有实时的保证ACID属性.但是我们使用了各种技术来保障可靠性和
数据的最终一致性。:异步事件
回复，settlement batches.  reconciliation  

笔者最近接收的一个系统存在一个分布式事务场景。一旦使用了分布式。就会增加
主调模块和被调模块的耦合。给升级带来困难。由于分布式事务的存在，可用性
降低了。用户请求有可能会因为分布式事务的资源准备，提交失败导致延迟的增加
为了完成一个事务。事务内的资源都变成了竞争资源。（数据库连接竞争，写失败
重试）这里也很可能为成为一个系统的瓶颈所在。业务场景本身不需要那么高的数据
一致性。因此可以去掉分布式事务。改由异步写入。数据不一致可以使用对账工具
和校验机制来保证数据的最终一致性。当然这种方法的缺点在于提高了业务逻辑的复杂度
。需要编写校验机制。同时需要写校验工具，额外增加了开发量。但是对于系统的性能
，对于系统间的松耦合还是有很大的好处的。



异步调用接口。

如果A使用同步方式调用组件B。那么A和B就和紧耦合的。这会影响扩展性。扩容A的时候
同样你得扩容B。（怎么理解？）如果B挂掉了那么A也就挂掉了？？？怎么说？？
如果使用异步方式，将请求用队列，广播消息，或者批量进程来处理。在B挂掉的情况下
A还能继续跑。
在变成的技术上，我们可以使用staged  event - driven  architecture   ，使用状态机
来进行请求的分解处理


这个有点难理解啊。采用同步调用方式，顶多是B挂掉A调用这个服务不可用而已。如果
是非关键路径请求还是可以照常跑下去的。如果是关键路径不管是同步异步都是会失败的
。采用异步的方式可以将请求使用队列的形式排个队。如果后端B某台server挂掉了
还可以将这些请求路由给其他B的服务器进行处理。同步的话这个就难实现了。而且本身
同步机制会使得请求串行执行，没法并行起来。机器CPU表示好闲有木有？
采用同步的方式，请求需要立马被处理。当请求大量来临的时候就需要扩容，采用异步就可以
在高峰时期顶下来。反正是采用异步处理的，请求都排着队。（SNG很多异步框架是指网络请求
可以批量发出去，对于后端的调用可以并行执行。不知道跟这里的并行是不是一码事啊尼马）
(spp  server 异步模式里是怎么缓存请求的。)


在所有层做虚拟化


例如物理机器和逻辑机器的虚拟化。一旦物理机器挂掉还可以把请求重新路由到其他机器上去
。网络层的虚拟化这边L5的使用有点类似，物理机器的ip和port被L5的Modid和Cmdid替代。



合理使用缓存。

对于读多写少的数据，可以使用缓存。配置，静态数据等都可以使用缓存。
真正的挑战在于读写都很多而且变化很剧烈的数据。对于缓存要合理使用，如果应用完全依赖
缓存的命中来工作，在重新负载均衡，迁移，或者冷启动（了解热启动）的时候缓存就会成为
一个头疼的问题这些在方案设计的时候都需要考虑到的。
好的缓存系统可以使请求以线性时间获取数据。










